---
title: "Resultados parciais"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

datasetsFolders <- Sys.glob("../results/training/*_common")

thresholds <- c("5", "10", "15", "20", "25", "30", "50", "75", "100", "150", "200", "250", "500")
classifier <- c("svmRadial", "J48", "knn", "nnet")
nBags <- c("50", "100", "150", "200")
fsAlgorithm <- c("infoGain", "chiSquared")
aggrAlgorithm <- c("mean")
```

## Resultados parciais

### Parâmetros testados:
- proporção de treino = 0.6
- número de genes = 5, 10, 15, 20, 25, 30, 50, 75, 100, 150, 200, 250, 500
- classificador = svmRadial, J48, knn, nnet, OneR
- número de bags = 50, 100, 150, 200
- algoritmo de seleção de atributos  = infoGain, chiSquared
- algortimo de agregação = média

## Número de genes
O número de genes parece não influenciar na performance. Porém, a maioria dos classificadores está atigindo quase 100% de acurácia. Isso deve ser investigado melhor. Dessa forma, nada podemos concluir, por enquanto.
```{r, echo=FALSE}
accuracies <- list()
modelsPaths <- paste("/models/", classifier, ".rds", sep = "")

for(modelPath in modelsPaths) {
  for(datasetPath in datasetsFolders) {
    model <- readRDS(paste(datasetPath, modelPath, sep = ""))
    
    for(aggrMethod in aggrAlgorithm) {
      for(fsAlg in fsAlgorithm) {
        for(nBag in nBags) {
          for(threshold in names(model[[aggrMethod]][[fsAlg]][[nBag]])) {
            acc <- max(model[[aggrMethod]][[fsAlg]][[nBag]][[threshold]][["results"]][["Accuracy"]], 
                       na.rm = TRUE)
            
            accuracies[[threshold]] <- c(accuracies[[threshold]], acc)
          }
        }
      }
    }
  }
}

boxplot(accuracies, 
        main = "Distribuição da acurácia em função do número de genes", 
        xlab = "Número de genes considerados no treinamento", 
        ylab = "Acurácia", 
        ylim=c(0, 1))
```

## Datasets

### Características
```{r, echo=FALSE}
datasetsPaths <- Sys.glob("~/Documents/codelab.nosync/biomarker_id/data/processed/train/*_common.rda")
data <- list()

for(datasetPath in datasetsPaths) {
  filenameParts <- strsplit(datasetPath, "/")[[1]]
  filenameWithExtension <- tail(filenameParts, n = 1)
  filenameWithExtensionParts <- strsplit(filenameWithExtension, "\\.")[[1]]
  filename <- filenameWithExtensionParts[1]
  
  load(datasetPath)
  
  nTumor <- sum(y == "Tumor")
  nNormal <- sum(y == "Normal")
  nSamples <- dim(x)[1]
  nGenes <- dim(x)[2]
  tumorRatio <- nTumor / nSamples
  
  data[[filename]] <- list("Number of tumor samples" = nTumor, 
                           "Number of normal samples" = nNormal, 
                           "Number of samples" = nSamples, 
                           "Number of genes" = nGenes, 
                           "Tumor Ratio" = tumorRatio)
}

data <- data.frame(t(sapply(data, c)))
print(data)
```

A maioria dos datasets e classificadores possuem um ótimo desempenho, estranhamente. Os métodos apresentam um desempenho quase constante na maioria dos modelos, independente do número de genes utilizados no treinamento. Apenas o dataset GSE71053 possui uma variação maior no desempenho de acordo com o classificador. Analisaremos esse datasets mais porfundamente em seguida. 

```{r, echo=FALSE, figures-side, fig.show="hold", out.width="33%"}
modelsPaths <- paste("/models/", classifier, ".rds", sep = "")

for(datasetPath in datasetsFolders) {
  dataset <- strsplit(datasetPath, "/")[[1]]
  dataset <- tail(dataset, n = 1)
  
  accuracies <- list()
  
  for(classif in classifier) {
    modelPath <- paste(datasetPath, "/models/", classif, ".rds", sep = "")
    model <- readRDS(modelPath)
    
    for(aggrMethod in aggrAlgorithm) {
      for(fsAlg in fsAlgorithm) {
        for(nBag in nBags) {
          for(threshold in names(model[[aggrMethod]][[fsAlg]][[nBag]])) {
            acc <- max(model[[aggrMethod]][[fsAlg]][[nBag]][[threshold]][["results"]][["Accuracy"]], 
                       na.rm = TRUE)
            
            accuracies[[classif]] <- c(accuracies[[classif]], acc)
          }
        }
      }
    }
  }
  
  boxplot(accuracies, 
        main = dataset, 
        xlab = "Classificador", 
        ylab = "Acurácia", 
        ylim=c(0, 1))
}
```

### GSE71053
A diferença do GSE71053 para os outros datasets é a quantidade de amostras com tumor em relação ao total. O GSE71053 é o único dataset com menor número de amostras com tumor do que amostras normais, o que *poderia* explicar a variação no desempenho. Na maioria dos casos, a acurácia entre **chiSquared** e **infoGain** são as mesmas em função do número de genes utilizados (threshold). O caso do modelo J48 é interessante, pois não importa o número de genes, o algoritmo não aprende a classificar corretamente as amostras. Nesse caso, a acurácia é constante (50%), ou seja, a classificação é aleatória. Como esperado, a maior variação de desempenho em todos os modelos, com exceção do J48, concentra-se nos números menores de threshold, aitingindo a acurácia máxima com 75 genes.

```{r, echo=FALSE}
library(ggplot2)
datasetFolder <- "../results/training/GSE71053_common"

for(classif in classifier) {
  modelPath <- paste(datasetFolder, "/models/", classif, ".rds", sep = "")
  model <- readRDS(modelPath)
  
  accuracies <- list()
  i <- 1
  
  for(aggrMethod in aggrAlgorithm) {
    for(fsAlg in fsAlgorithm) {
      for(nBag in nBags) {
        for(threshold in names(model[[aggrMethod]][[fsAlg]][[nBag]])) {
          acc <- max(model[[aggrMethod]][[fsAlg]][[nBag]][[threshold]][["results"]][["Accuracy"]], 
                     na.rm = TRUE)
          
          accuracies[[i]] <- list("AggregationMethod" = aggrMethod, 
                                  "FeatureSelection" = fsAlg, 
                                  "NumberOfBags" = nBag, 
                                  "Threshold" = threshold, 
                                  "Accuracy" = acc)
          i <- i + 1
        }
      }
    }
  }
  
  rm(threshold, fsAlg, nBag)
  
  data <- data.frame(t(sapply(accuracies, c)))
  data$Threshold <- as.numeric(data$Threshold)
  data$Accuracy <- as.numeric(data$Accuracy)
  data$NumberOfBags <- as.numeric(data$NumberOfBags)
  data$FeatureSelection <- as.factor(unlist(data$FeatureSelection))
  
  data <- aggregate(Accuracy ~ (Threshold + FeatureSelection), data, max)
  
  g <- ggplot(data, aes(Threshold, Accuracy, colour = FeatureSelection))
  g <- g + geom_line() + geom_point()
  g <- g + ggtitle(classif)
  g <- g + ylim(0, 1)
  print(g)
}
```
